{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19d3911e",
   "metadata": {},
   "source": [
    "<!-- Header -->\n",
    "<p style=\"background-color:#2F4F4F; font-family:Georgia, serif; color:#FAF0E6; font-size:160%; text-align:center; border-radius:12px; padding:10px;\">\n",
    "üèòÔ∏è Dataset Overview\n",
    "</p>\n",
    "\n",
    "<!-- Dataset Description -->\n",
    "<p style=\"font-family:Verdana, sans-serif; font-size:110%; color:#333;\">\n",
    "üìä <b>Forecasting Residential Property Prices Using Supervised Learning</b> contains detailed information on residential properties such as size, location, and condition. The project aims to develop a supervised learning model that can accurately forecast housing prices based on these attributes.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-family:Verdana, sans-serif; font-size:110%; color:#333;\">\n",
    "This dataset is used to train a regression model that learns the relationships between features like <b>square footage, number of bedrooms/bathrooms, year built, location</b>, and the target variable <b>price</b>.\n",
    "</p>\n",
    "\n",
    "<!-- Objectives -->\n",
    "<p style=\"font-family:Verdana, sans-serif; font-size:110%; color:#333;\">\n",
    "üéØ <b>Objective:</b> Develop a machine learning model to predict the selling price of a house using structured real estate data.\n",
    "</p>\n",
    "\n",
    "<!-- Dataset Attributes -->\n",
    "<p style=\"background-color:#2F4F4F; font-family:Georgia, serif; color:#FAF0E6; font-size:150%; text-align:center; border-radius:12px; padding:10px;\">\n",
    "üìù Dataset Attributes\n",
    "</p>\n",
    "\n",
    "<table style=\"width:100%; border-collapse: collapse; font-family:Verdana, sans-serif; font-size:100%; color:#333;\">\n",
    "  <thead style=\"background-color:#2F4F4F; color:#FAF0E6;\">\n",
    "    <tr>\n",
    "      <th style=\"padding:10px; border: 1px solid #ccc;\">Variable</th>\n",
    "      <th style=\"padding:10px; border: 1px solid #ccc;\">Description</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr><td style=\"padding:8px; border: 1px solid #ccc;\">date</td><td style=\"padding:8px; border: 1px solid #ccc;\">Date of property listing</td></tr>\n",
    "    <tr><td style=\"padding:8px; border: 1px solid #ccc;\">price</td><td style=\"padding:8px; border: 1px solid #ccc;\">Selling price of the house (target)</td></tr>\n",
    "    <tr><td style=\"padding:8px; border: 1px solid #ccc;\">bedrooms</td><td style=\"padding:8px; border: 1px solid #ccc;\">Number of bedrooms</td></tr>\n",
    "    <tr><td style=\"padding:8px; border: 1px solid #ccc;\">bathrooms</td><td style=\"padding:8px; border: 1px solid #ccc;\">Number of bathrooms</td></tr>\n",
    "    <tr><td style=\"padding:8px; border: 1px solid #ccc;\">sqft_living</td><td style=\"padding:8px; border: 1px solid #ccc;\">Living area in square feet</td></tr>\n",
    "    <tr><td style=\"padding:8px; border: 1px solid #ccc;\">sqft_lot</td><td style=\"padding:8px; border: 1px solid #ccc;\">Total lot size in square feet</td></tr>\n",
    "    <tr><td style=\"padding:8px; border: 1px solid #ccc;\">floors</td><td style=\"padding:8px; border: 1px solid #ccc;\">Number of floors in the house</td></tr>\n",
    "    <tr><td style=\"padding:8px; border: 1px solid #ccc;\">waterfront</td><td style=\"padding:8px; border: 1px solid #ccc;\">Whether the house is on a waterfront (0/1)</td></tr>\n",
    "    <tr><td style=\"padding:8px; border: 1px solid #ccc;\">view</td><td style=\"padding:8px; border: 1px solid #ccc;\">Quality of the view from the house</td></tr>\n",
    "    <tr><td style=\"padding:8px; border: 1px solid #ccc;\">condition</td><td style=\"padding:8px; border: 1px solid #ccc;\">Overall condition of the house (1‚Äì5)</td></tr>\n",
    "    <tr><td style=\"padding:8px; border: 1px solid #ccc;\">sqft_above</td><td style=\"padding:8px; border: 1px solid #ccc;\">Square footage of the house apart from the basement</td></tr>\n",
    "    <tr><td style=\"padding:8px; border: 1px solid #ccc;\">sqft_basement</td><td style=\"padding:8px; border: 1px solid #ccc;\">Basement area in square feet</td></tr>\n",
    "    <tr><td style=\"padding:8px; border: 1px solid #ccc;\">yr_built</td><td style=\"padding:8px; border: 1px solid #ccc;\">Year the house was built</td></tr>\n",
    "    <tr><td style=\"padding:8px; border: 1px solid #ccc;\">yr_renovated</td><td style=\"padding:8px; border: 1px solid #ccc;\">Year the house was renovated (if any)</td></tr>\n",
    "    <tr><td style=\"padding:8px; border: 1px solid #ccc;\">street</td><td style=\"padding:8px; border: 1px solid #ccc;\">Street address of the house</td></tr>\n",
    "    <tr><td style=\"padding:8px; border: 1px solid #ccc;\">city</td><td style=\"padding:8px; border: 1px solid #ccc;\">City where the house is located</td></tr>\n",
    "    <tr><td style=\"padding:8px; border: 1px solid #ccc;\">statezip</td><td style=\"padding:8px; border: 1px solid #ccc;\">State and ZIP code</td></tr>\n",
    "    <tr><td style=\"padding:8px; border: 1px solid #ccc;\">country</td><td style=\"padding:8px; border: 1px solid #ccc;\">Country of the property</td></tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "<!-- End Note -->\n",
    "<p style=\"font-family:Verdana, sans-serif; font-size:110%; color:#333; margin-top:20px;\">\n",
    "‚úÖ This dataset enables training of supervised regression models to forecast house prices and provide actionable insights in the real estate domain.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1914794a",
   "metadata": {},
   "source": [
    "<style>\n",
    "  body, html {\n",
    "    margin: 0;\n",
    "    padding: 0;\n",
    "    width: 100%;\n",
    "  }\n",
    "  .container {\n",
    "    width: 100%;\n",
    "    padding: 10px 20px;\n",
    "    background: #f0f4f8;\n",
    "    font-family: 'Segoe UI', sans-serif;\n",
    "    box-sizing: border-box;\n",
    "  }\n",
    "  h1 {\n",
    "    text-align: center;\n",
    "    color: #2c3e50;\n",
    "    margin: 20px 0;\n",
    "  }\n",
    "  .step {\n",
    "    background-color: #ffffff;\n",
    "    border-left: 6px solid #3498db;\n",
    "    padding: 15px 20px;\n",
    "    margin: 10px 0;\n",
    "    border-radius: 6px;\n",
    "    box-shadow: 0 2px 4px rgba(0,0,0,0.05);\n",
    "  }\n",
    "  .step:nth-child(even) {\n",
    "    border-left-color: #2ecc71;\n",
    "    background-color: #fafffc;\n",
    "  }\n",
    "  .step h2 {\n",
    "    margin: 0 0 5px;\n",
    "    font-size: 18px;\n",
    "    color: #2c3e50;\n",
    "  }\n",
    "  .step p {\n",
    "    margin: 0;\n",
    "    font-size: 14px;\n",
    "    color: #444;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "<div class=\"container\">\n",
    "  <h1>Machine Learning Pipeline</h1>\n",
    "\n",
    "  <div class=\"step\">\n",
    "    <h2>1. Data Collection</h2>\n",
    "    <p>Load data from files</p>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"step\">\n",
    "    <h2>2. Data  Cleaning</h2>\n",
    "    <p>Handle missing values, drop unnecessary columns, and remove duplicates.</p>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"step\">\n",
    "    <h2>3. Exploratory Data Analysis (EDA)</h2>\n",
    "    <p>Visualize distributions, correlations, and trends using plots and summary statistics.</p>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"step\">\n",
    "    <h2>4. Outlier Detection & Removal</h2>\n",
    "    <p>Detect and remove outliers using quantile methods and box plots.</p>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"step\">\n",
    "    <h2>5. Feature Engineering</h2>\n",
    "    <p>Create meaningful features, extract datetime elements, or combine columns.</p>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"step\">\n",
    "    <h2>6.Log - Transformation</h2>\n",
    "    <p>Apply Log - transformation to stabilize variance and normalize skewed features.</p>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"step\">\n",
    "    <h2>7. Encoding</h2>\n",
    "    <p>Convert categorical variables using Label Encoding or One-Hot Encoding.</p>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"step\">\n",
    "    <h2>8. Train-Test Split</h2>\n",
    "    <p>Split data into training and testing sets to evaluate generalization.</p>\n",
    "  </div>\n",
    "\n",
    " <div class=\"step\">\n",
    "    <h2>9. Train-Test Split</h2>\n",
    "    <p> Features Selections .</p>\n",
    "  </div>\n",
    "\n",
    "\n",
    "  <div class=\"step\">\n",
    "    <h2>10. Model Training</h2>\n",
    "    <p>Train machine learning models such as Logistic Regression, Random Forest, or XGBoost.</p>\n",
    "  </div>\n",
    "\n",
    " <div class=\"step\">\n",
    "  <h2>10. Evaluation</h2>\n",
    "  <p>\n",
    "    Assess the model's performance using the following regression metrics:\n",
    "  </p>\n",
    "  <ul>\n",
    "    <li>Adjusted R¬≤ (Adjusted R-squared)</li>\n",
    "    <li>Mean Absolute Error (MAE)</li>\n",
    "    <li>Mean Squared Error (MSE)</li>\n",
    "    <li>R¬≤ (R-squared)</li>\n",
    "  </ul>\n",
    "  <p>\n",
    "    Additionally, visualize the residuals plot to check for patterns and validate model assumptions.\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "  <div class=\"step\">\n",
    "    <h2>11. Hyperparameter Tuning and Model Selection</h2>\n",
    "    <p> Train the model using optimized hyperparameters to improve performance.  </p>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c16cbb2",
   "metadata": {},
   "source": [
    "<!-- Section Header -->\n",
    "<p style=\"background-color:#1E3D59; font-family:Georgia, serif; color:#FDFEFE; font-size:150%; text-align:center; border-radius:12px; padding:10px;\">\n",
    "üìö  Import Important Libraries and Data Loading\n",
    "</p>\n",
    "\n",
    "<!-- Description -->\n",
    "<p style=\"font-family:Verdana, sans-serif; font-size:110%; color:#333;\">\n",
    "To perform data analysis, visualization, and modeling efficiently, we need to import several essential Python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b47f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as sp\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import the dataset\n",
    "df = pd.read_csv('/Users/mac/Desktop/DATA/Regression_project.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbbb224",
   "metadata": {},
   "source": [
    "<!-- Section Header -->\n",
    "<p style=\"background-color:#1E3D59; font-family:Georgia, serif; color:#FDFEFE; font-size:150%; text-align:center; border-radius:12px; padding:10px;\">\n",
    "üßπ Data Cleaning\n",
    "</p>\n",
    "\n",
    "<!-- Description -->\n",
    "<p style=\"font-family:Verdana, sans-serif; font-size:110%; color:#333;\">\n",
    "Handle missing values, remove duplicates, and fix inconsistencies to ensure clean and reliable data.\n",
    "</p>\n",
    "\n",
    "<!-- Code Block -->\n",
    "<pre style=\"background-color:#f4f4f4; padding:12px; border-radius:8px; font-size:105%;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815200f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking shape of data\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0046dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking the unique values in each column\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2b7d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98af41db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking missing value \n",
    "df.isna().sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104fdef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for information about each column\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c10497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking duplicate values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be341a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  describe the data\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb716d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserting data zipcode from statezip columns\n",
    "df['zip'] = df['statezip'].str.split().str[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d440726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeing the correlation between the price and the other features\n",
    "df.corr(numeric_only=True)['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820dc76-303c-40ff-966c-305efc3440bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "df.drop(columns=['date','country','street','street','statezip','city'],inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae0e8da-35f2-4469-b3e8-3b27d92a59c7",
   "metadata": {},
   "source": [
    "\n",
    "<p style=\"background-color:#1E3D59; font-family:Georgia, serif; color:#FDFEFE; font-size:150%; text-align:center; border-radius:12px; padding:10px;\">\n",
    "üìä Exploratory Data Analysis (EDA)\n",
    "</p>\n",
    "\n",
    "<!-- Description -->\n",
    "<p style=\"font-family:Verdana, sans-serif; font-size:110%; color:#333;\">\n",
    "EDA helps uncover patterns, spot anomalies, and understand the structure of the dataset before building any model. It includes statistical summaries and visualizations.\n",
    "</p>\n",
    "\n",
    "<!-- Code Block -->\n",
    "<pre style=\"background-color:#f4f4f4; padding:12px; border-radius:8px; font-size:105%;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da4b2f-b169-4e05-b44e-7cd330792f11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create plots for continuous variables\n",
    "for col in numerical_features:\n",
    "    plt.figure(figsize=(20, 5))\n",
    "\n",
    "    # Distribution Plot\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.histplot(df[col].dropna(), bins=30, kde=True, color='blue')\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "\n",
    "    # Box Plot\n",
    "    plt.subplot(1, 3, 2)\n",
    "    sns.boxplot(y=df[col].dropna(), color='orange')\n",
    "    plt.title(f\"Box Plot of {col}\")\n",
    "\n",
    "    # Integral Plot (Cumulative Sum)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(np.cumsum(df[col].fillna(0).values), color='green')\n",
    "    plt.title(f\"Cumulative Sum of {col}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a8010-c652-4f08-8375-3ff87bcbe5cd",
   "metadata": {},
   "source": [
    "### EDA of Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae53ec4f-c5a4-4bb4-9ee8-05de236f0719",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for col in categorical_features:\n",
    "    plt.figure(figsize=(20, 5))\n",
    "\n",
    "    # Bar Plot\n",
    "    plt.subplot(1, 3, 1)\n",
    "    df[col].value_counts().plot(kind='bar', color='purple')\n",
    "    plt.title(f\"Bar Plot of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "\n",
    "    # Pie Chart ‚Äì only for ‚â§10 unique categories\n",
    "    if df[col].nunique() <= 10:\n",
    "        plt.subplot(1, 3, 2)\n",
    "        df[col].value_counts().plot(\n",
    "            kind='pie',\n",
    "            autopct='%1.1f%%',\n",
    "            colors=sns.color_palette('pastel'),\n",
    "            ylabel=''  # remove label\n",
    "        )\n",
    "        plt.title(f\"Pie Chart of {col}\")\n",
    "\n",
    "    # Box Plot of Category vs Price\n",
    "    if 'price' in df.columns:\n",
    "        plt.subplot(1, 3, 3)\n",
    "        sns.boxplot(x=df[col], y=df['price'], palette='Set2')\n",
    "        plt.title(f\"Box Plot: {col} vs Price\")\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c368c231",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459b38a3",
   "metadata": {},
   "source": [
    "<!-- Section Header -->\n",
    "<p style=\"background-color:#1E3D59; font-family:Georgia, serif; color:#FDFEFE; font-size:150%; text-align:center; border-radius:12px; padding:10px;\">\n",
    "üö´ Outlier Detection and Removal\n",
    "</p>\n",
    "\n",
    "<!-- Description -->\n",
    "<p style=\"font-family:Verdana, sans-serif; font-size:110%; color:#333;\">\n",
    "Outliers can skew the results of your analysis and impact model performance. Here, we use the Interquartile Range (IQR) method to detect and remove extreme values.\n",
    "</p>\n",
    "\n",
    "<!-- Code Block -->\n",
    "<pre style=\"background-color:#f4f4f4; padding:12px; border-radius:8px; font-size:105%;\">\n",
    "<code># Detect and remove outliers using Quantile method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ec578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Record the original number of rows\n",
    "original_count = len(df)\n",
    "\n",
    "#  Quantile filtering (remove 2% from top and bottom)\n",
    "q_low = df['price'].quantile(0.015)\n",
    "q_high = df['price'].quantile(0.985)\n",
    "\n",
    "df = df[(df['price'] >= q_low) & (df['price'] <= q_high)]\n",
    "\n",
    "# Record the new number of rows\n",
    "filtered_count = len(df)\n",
    "\n",
    "# Calculate percentage change\n",
    "percent_change = ((original_count - filtered_count) / original_count) * 100\n",
    "\n",
    "print(f\"Rows before filtering: {original_count}\")\n",
    "print(f\"Rows after filtering: {filtered_count}\")\n",
    "print(f\"Percentage of rows removed: {percent_change:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcb57de",
   "metadata": {},
   "source": [
    "<!-- Section Header -->\n",
    "<p style=\"background-color:#1E3D59; font-family:Georgia, serif; color:#FDFEFE; font-size:150%; text-align:center; border-radius:12px; padding:10px;\">\n",
    "üõ†Ô∏è Feature Engineering\n",
    "</p>\n",
    "\n",
    "<!-- Description -->\n",
    "<p style=\"font-family:Verdana, sans-serif; font-size:110%; color:#333;\">\n",
    "Feature engineering involves creating new features or modifying existing ones to improve the performance of machine learning models. This can include handling missing values, encoding categorical variables, extracting date components, binning, interaction terms, and more.\n",
    "</p>\n",
    "\n",
    "<!-- Code Block -->\n",
    "<pre style=\"background-color:#f4f4f4; padding:12px; border-radius:8px; font-size:105%;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d0794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new columns with total_sqft and waterfront_view\n",
    "df['total_sqft'] = df['sqft_basement']+df['sqft_living']\n",
    "df['waterfront_view'] = df['waterfront'] * df['view']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5020e30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate average price per ZIP\n",
    "zip_avg_price = df.groupby('zip')['price'].mean()\n",
    "\n",
    "# 2. Create 3 tiers based on tertiles\n",
    "zip_tiers = pd.qcut(zip_avg_price, q=3, labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "# 3. Map tiers back to original datafram\n",
    "df['zip_tier'] = df['zip'].map(zip_tiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9561c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bedrooom-group\n",
    "def bedroom_bins(bed):\n",
    "    if bed == 0:\n",
    "        return 'studio_or_missing'\n",
    "    elif bed <= 2:\n",
    "        return 'small'\n",
    "    elif bed <= 4:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'large'\n",
    "\n",
    "df['bedroom_group'] = df['bedrooms'].apply(bedroom_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959949cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bathroom_group\n",
    "def bathroom_bins(bath):\n",
    "    if bath == 0:\n",
    "        return 'none'\n",
    "    elif bath <= 1.5:\n",
    "        return 'small'\n",
    "    elif bath <= 3:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'large'\n",
    "\n",
    "df['bathroom_group'] = df['bathrooms'].apply(bathroom_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce98633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_group(cond):\n",
    "    if cond <= 2:\n",
    "        return 'poor'\n",
    "    elif cond == 3:\n",
    "        return 'average'\n",
    "    else:\n",
    "        return 'good'\n",
    "\n",
    "df['condition_group'] = df['condition'].apply(condition_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3890db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create house age column \n",
    "df['house_age'] = 2025 - df['yr_built']\n",
    "\n",
    "# Define bins and labels\n",
    "bins = [0, 10, 30, 60, 100, df['house_age'].max()]\n",
    "labels = ['New ', 'Modern','Mid_Age','Old', 'Very Old'] # ['New (0‚Äì10)', 'Modern (11‚Äì30)', 'Mid-age (31‚Äì60)', 'Old (61‚Äì100)', 'Very Old (100+)]\n",
    "\n",
    "# Apply binning\n",
    "df['house_age_tier'] = pd.cut(df['house_age'], bins=bins, labels=labels, right=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c6332a-55af-4e24-a6a7-6bf13c6152c8",
   "metadata": {},
   "source": [
    "#### Transformations of the numerical column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ed469",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Log transform  to the price , total_sqft, sqft_lot\n",
    "df['price'] = np.log1p(df['price'])\n",
    "df['total_sqft'] = np.log1p(df['total_sqft'])\n",
    "df['sqft_lot'] = np.log1p(df['sqft_lot'])\n",
    "df['sqft_above'] = np.log1p(df['sqft_above'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a85da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "level_col = ['waterfront_view', 'zip_tier', 'bedroom_group',\n",
    "             'bathroom_group', 'condition_group', 'house_age_tier']\n",
    "\n",
    "# Step 1: Create the encoder with safe handling of unknown categories\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# Step 2: Fit and transform on selected columns\n",
    "df[level_col] = encoder.fit_transform(df[level_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d989d01",
   "metadata": {},
   "source": [
    "<!-- Section Header -->\n",
    "<p style=\"background-color:#1E3D59; font-family:Georgia, serif; color:#FDFEFE; font-size:150%; text-align:center; border-radius:12px; padding:10px;\">\n",
    "  Feature Selection\n",
    "</p>\n",
    "\n",
    "<!-- Description -->\n",
    "<p style=\"font-family:Verdana, sans-serif; font-size:110%; color:#333;\">\n",
    "  Using <strong>forward selection</strong>, <strong>backward elimination</strong>, and <strong>stepwise selection</strong> methods, we will identify the most significant features to include in our model.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8db10a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['price','zip'])\n",
    "y = df['price']\n",
    "\n",
    "# Optional: Scale numeric features\n",
    "X = pd.get_dummies(X, drop_first=True)  \n",
    "X = sm.add_constant(X)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1940e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward selections:\n",
    "def forward_selection(X, y):\n",
    "    initial_features = []\n",
    "    remaining_features = list(X.columns)\n",
    "    best_features = []\n",
    "    current_score, best_new_score = float('inf'), float('inf')\n",
    "\n",
    "    while remaining_features:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remaining_features:\n",
    "            try:\n",
    "                model = sm.OLS(y, sm.add_constant(X[initial_features + [candidate]])).fit()\n",
    "                score = model.aic\n",
    "                scores_with_candidates.append((score, candidate))\n",
    "            except:\n",
    "                continue\n",
    "        scores_with_candidates.sort()\n",
    "        best_new_score, best_candidate = scores_with_candidates[0]\n",
    "\n",
    "        if best_new_score < current_score:\n",
    "            remaining_features.remove(best_candidate)\n",
    "            initial_features.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "            best_features = initial_features.copy()\n",
    "        else:\n",
    "            break\n",
    "    return best_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525e0f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward selections :\n",
    "def backward_elimination(X, y):\n",
    "    features = list(X.columns)\n",
    "    while len(features) > 0:\n",
    "        X_train = sm.add_constant(X[features])\n",
    "        model = sm.OLS(y, X_train).fit()\n",
    "        pvalues = model.pvalues[1:]  # exclude constant\n",
    "        max_pval = pvalues.max()\n",
    "        if max_pval > 0.05:\n",
    "            excluded_feature = pvalues.idxmax()\n",
    "            features.remove(excluded_feature)\n",
    "        else:\n",
    "            break\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995f2bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stepwise_selection\n",
    "def stepwise_selection(X, y):\n",
    "    included = []\n",
    "    while True:\n",
    "        changed = False\n",
    "        # Forward step\n",
    "        excluded = list(set(X.columns) - set(included))\n",
    "        new_pvals = pd.Series(index=excluded, dtype=float)\n",
    "        for new_col in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(X[included + [new_col]])).fit()\n",
    "            new_pvals[new_col] = model.pvalues[new_col]\n",
    "        min_pval = new_pvals.min()\n",
    "        if min_pval < 0.05:\n",
    "            best_feature = new_pvals.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed = True\n",
    "\n",
    "        # Backward step\n",
    "        model = sm.OLS(y, sm.add_constant(X[included])).fit()\n",
    "        pvalues = model.pvalues.iloc[1:]  # exclude constant\n",
    "        max_pval = pvalues.max()\n",
    "        if max_pval > 0.05:\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            changed = True\n",
    "\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae24b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the features that are selected by  all these methods\n",
    "forward_features = forward_selection(X, y)\n",
    "print(\"üîº Forward Selection Features:\\n\", forward_features)\n",
    "\n",
    "backward_features = backward_elimination(X, y)\n",
    "print(\"üîΩ Backward Elimination Features:\\n\", backward_features)\n",
    "\n",
    "stepwise_features = stepwise_selection(X, y)\n",
    "print(\"üîÅ Stepwise Selection Features:\\n\", stepwise_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1689120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove specified columns from df\n",
    "columns_to_remove = ['bedrooms', 'bathrooms', 'waterfront', 'view', 'condition','sqft_basement','sqft_living','house_age','yr_built','yr_renovated','zip']\n",
    "df.drop(columns=columns_to_remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ae6cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the remaining columns\n",
    "df.columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc14aa83",
   "metadata": {},
   "source": [
    "<!-- Section Header -->\n",
    "<p style=\"background-color:#1E3D59; font-family:Georgia, serif; color:#FDFEFE; font-size:150%; text-align:center; border-radius:12px; padding:10px;\">\n",
    "üìà Univariate Regression Analysis\n",
    "</p>\n",
    "\n",
    "<!-- Description -->\n",
    "<p style=\"font-family:Verdana, sans-serif; font-size:110%; color:#333;\">\n",
    "Univariate regression examines the relationship between the target variable and a single predictor. Here, we analyze the impact of individual features like <b>sqft_living</b>, <b>total_sqft</b>, and <b>price_per_sqft_lot</b> on the house price.\n",
    "</p>\n",
    "\n",
    "<!-- Feature List -->\n",
    "<ul style=\"font-family:Verdana, sans-serif; font-size:105%; color:#555;\">\n",
    "  <li><b>sqft_living</b> ‚Äì Total interior livable space in square feet</li>\n",
    "  <li><b>total_sqft</b> ‚Äì Combined area including basement and extensions</li>\n",
    "  <li><b>price_per_sqft_lot</b> ‚Äì Cost efficiency based on lot area</li>\n",
    "</ul>\n",
    "\n",
    "<!-- Code Block Placeholder -->\n",
    "<pre style=\"background-color:#f4f4f4; padding:12px; border-radius:8px; font-size:105%;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801409b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Numerical features (excluding target)\n",
    "num_features = [\n",
    "    'sqft_lot',\n",
    "    'total_sqft'\n",
    "]\n",
    "\n",
    "# Target variable\n",
    "y = df['price']\n",
    "\n",
    "# Loop through each feature\n",
    "for col in num_features:\n",
    "    X = df[[col]]\n",
    "    X_const = sm.add_constant(X)\n",
    "    \n",
    "    model = sm.OLS(y, X_const).fit()\n",
    "    y_pred = model.predict(X_const)\n",
    "    residuals = y - y_pred\n",
    "\n",
    "    # Scatter + Regression Line Plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.scatterplot(x=df[col], y=y, alpha=0.5, label=\"Actual\")\n",
    "    plt.plot(df[col], y_pred, color='red', label=\"Regression Line\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Price')\n",
    "    plt.title(f'Price vs {col} (R¬≤ = {model.rsquared:.3f})')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # QQ Plot of Residuals\n",
    "    sm.qqplot(residuals, line='45', fit=True)\n",
    "    plt.title(f'QQ Plot of Residuals: Price ~ {col}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Regression Summary\n",
    "    print(f\"üìä Summary for {col}:\\n\")\n",
    "    print(model.summary())\n",
    "    print(\"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95878e12",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<!-- Section Header -->\n",
    "<p style=\"background-color:#1E3D59; font-family:Georgia, serif; color:#FDFEFE; font-size:150%; text-align:center; border-radius:12px; padding:10px;\">\n",
    "üìà Model Training\n",
    "</p>\n",
    "\n",
    "<!-- Subheadings -->\n",
    "<p style=\"font-family:Verdana, sans-serif; font-size:115%; color:#1E3D59;\"><b>üîπ Train-Test Split</b></p>\n",
    "\n",
    "<p style=\"font-family:Verdana, sans-serif; font-size:115%; color:#1E3D59;\"><b>üîπ Model Fitting</b></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6521c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit with scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b907797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from  sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def classify(model, X, y):\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Fit with scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Fit model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict on test\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Metrics\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    adj_r2 = 1 - (1 - r2) * (len(y_test) - 1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "\n",
    "    print(f\"üîπ R¬≤ Score:        {r2:.4f}\")\n",
    "    print(f\"üîπ Adjusted R¬≤:     {adj_r2:.4f}\")\n",
    "    print(f\"üîπ MSE:             {mse:.2f}\")\n",
    "    print(f\"üîπ Accuracy Score:  {model.score(X_test_scaled, y_test) * 100:.2f}%\")\n",
    "\n",
    "    # Cross validation\n",
    "    pipeline = make_pipeline(MinMaxScaler(), model)\n",
    "    scores = cross_val_score(pipeline, X, y, cv=5, scoring='r2')\n",
    "    print(f\"üîπ Cross-Validation R¬≤: {np.mean(scores) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eae5d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model1 = LinearRegression()\n",
    "classify(model1, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b23e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model2 = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "classify(model2, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d04ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model3 = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "classify(model3, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4bb535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "model4= XGBRegressor(n_estimator =100 ,learning_rate =0.1 ,random_state=42 )\n",
    "classify(model4, X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83232271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model5 = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42)\n",
    "classify(model5, X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f0efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "model6 = CatBoostRegressor(verbose=0, random_state=42)\n",
    "classify(model6, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0594d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model1, model2,model3,model4,model5, model6]\n",
    "for i, m in enumerate(models, 1):\n",
    "    print(f\"\\nüî∏Model {i}: {type(m).__name__}üî∏\")\n",
    "    classify(m, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b36670b",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9577576e",
   "metadata": {},
   "source": [
    " we select the best model from the result \n",
    "1. LinearRegression\n",
    "2.CatBoostRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d251f963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model1 = LinearRegression()\n",
    "classify(model1, X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b53312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumptions of Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 1. Fit Linear Regression\n",
    "linear = LinearRegression()\n",
    "linear.fit(X_train, y_train)\n",
    "y_pred = linear.predict(X_test)\n",
    "\n",
    "# 2. Calculate residuals\n",
    "residual_1 = y_test - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214dedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Linearity check ---\n",
    "# Plot actual vs predicted\n",
    "plt.scatter(y_pred, y_test, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Linearity check: Predicted vs Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff0ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Independence of errors ---\n",
    "# Usually checked by study design; if data is time series, check autocorrelation:\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "plot_acf(residual_1)\n",
    "plt.title(\"Autocorrelation of residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d45d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Homoscedasticity ---\n",
    "# Plot residuals vs predicted values\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(y_pred, residual_1, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"residual_1\")\n",
    "plt.title(\"Homoscedasticity check: residual_1 vs Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385462e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 4. Normality of errors ---\n",
    "# Histogram +\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(residual_1, kde=True)\n",
    "plt.title(\"Histogram of residual_1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec1765",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_const = sm.add_constant(X_train)  # Add constant for OLS\n",
    "ols_model = sm.OLS(y_train, X_const).fit()\n",
    "influence = ols_model.get_influence()\n",
    "cooks_d, _ = influence.cooks_distance\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.stem(np.arange(len(cooks_d)), cooks_d, markerfmt=\".\")\n",
    "plt.axhline(4 / len(X_train), color='red', linestyle='--', label='Threshold (4/n)')\n",
    "plt.title(\"Cook's Distance (OLS Approximation for Ridge)\")\n",
    "plt.xlabel(\"Observation Index\")\n",
    "plt.ylabel(\"Cook's Distance\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0f5e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# Step 1: Add constant term\n",
    "X_const = sm.add_constant(X_train_scaled)  # X_train_scaled is a NumPy array\n",
    "\n",
    "# Step 2: Create DataFrame with appropriate column names\n",
    "X_const_df = pd.DataFrame(X_const, columns=['const'] + list(X_train.columns))\n",
    "\n",
    "# Step 3: Compute VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['feature'] = X_const_df.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(X_const_df.values, i)\n",
    "                   for i in range(X_const_df.shape[1])]\n",
    "\n",
    "# Step 4: View VIF scores\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca7e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AIC:\", ols_model.aic)\n",
    "print(\"BIC:\", ols_model.bic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd79dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit linear regression model\n",
    "linear = LinearRegression()\n",
    "linear.fit(X_train_scaled,y_train)\n",
    "# Get absolute values of coefficients as feature importance\n",
    "feature_importances = np.abs(linear.coef_)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(range(len(feature_importances)), feature_importances, color='skyblue')\n",
    "plt.yticks(range(len(X.columns)), X.columns)\n",
    "plt.xlabel(\"Feature Importance (|Coefficient|)\")\n",
    "plt.title(\"Linear Regression Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d1cf9f",
   "metadata": {},
   "source": [
    "### Asuumption of model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6533b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "cat_model = CatBoostRegressor(verbose=0, random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'iterations': [10,25,50,100,200, 500],\n",
    "    'learning_rate': [0.001, 0.05, 0.1,0.3,0.4,0.5,0.8,1],\n",
    "    'depth': [4,5,6,7,8,10,15],\n",
    "    'l2_leaf_reg': [1,2,3,4,5,7,9]\n",
    "}\n",
    "\n",
    "random_search_cat = RandomizedSearchCV(\n",
    "    estimator=cat_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    scoring='r2',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search_cat.fit(X, y)\n",
    "\n",
    "print(\"üê± CatBoost Best Params:\", random_search_cat.best_params_)\n",
    "print(\"üê± CatBoost Best R¬≤ Score:\", random_search_cat.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014a1d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cat Boost Regressor with best parameters\n",
    "from catboost import CatBoostRegressor\n",
    "model7 = CatBoostRegressor(verbose=0,learning_rate=0.1,l2_leaf_reg=9,iterations=500,depth=4, random_state=42)\n",
    "classify(model7, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acae6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Analysis\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = CatBoostRegressor(verbose=0,learning_rate=0.1,l2_leaf_reg=9,iterations=500,depth=4, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "residual_2 = y_test - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0bfcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.residplot(x=y_pred, y=residual_2, lowess=True, line_kws={'color': 'red'})\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"Residual_2\")\n",
    "plt.title(\"Residual_2 vs Fitted\")\n",
    "plt.axhline(0, linestyle='--', color='black')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818b4d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distplot of residuals\n",
    "fig_size=(8,6)\n",
    "sns.histplot(residual_2, kde=True)\n",
    "plt.title(\"Histogram of Residuals\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ Plot\n",
    "sm.qqplot(residual_2, line='45', fit=True)\n",
    "plt.title(\"Q-Q Plot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f28f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot feature importance\n",
    "feature_importances = model.get_feature_importance()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(range(len(feature_importances)), feature_importances)\n",
    "plt.yticks(range(len(X.columns)), X.columns)\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"CatBoost Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c4901",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281aabd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîé Model Performance Summary\n",
    "\n",
    "# ‚ñ∂ Linear Regression:\n",
    "# - R¬≤ Score: 0.5575 ‚Üí Model explains 55.75% of target variance.\n",
    "# - MSE: 0.11 ‚Üí Average error between predicted and actual values.\n",
    "# - Cross-Validation R¬≤: 53.44% ‚Üí Slightly lower generalization ability.\n",
    "\n",
    "# ‚ñ∂ CatBoost Regressor:\n",
    "# - R¬≤ Score: 0.7868 ‚Üí Explains 78.68% of target variance.\n",
    "# - MSE: 0.05 ‚Üí Better accuracy, smaller prediction error.\n",
    "# - Cross-Validation R¬≤: 75.61% ‚Üí Strong and stable performance on unseen data.\n",
    "\n",
    "# üìä Multicollinearity Check (VIF):\n",
    "# - All VIF < 3.61 ‚Üí No serious multicollinearity issues in features.\n",
    "# - Highest VIF: 'sqft_above' ‚âà 3.61 ‚Üí Still acceptable.\n",
    "\n",
    "# ‚úÖ Final Selection:\n",
    "# CatBoost chosen as the best model due to:\n",
    "# - Higher R¬≤ and lower MSE.\n",
    "# - Strong CV performance.s\n",
    "# - Robustness to feature collinearity and requires less tuning.\n",
    "\n",
    "# ‚úî Suitable for real-world deployment with stable, accurate results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
